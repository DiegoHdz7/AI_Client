{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# fetch dataset \n",
    "glioma_grading_clinical_and_mutation_features = fetch_ucirepo(id=759) \n",
    "\n",
    "# Convert data to Pandas DataFrame\n",
    "X = pd.DataFrame(glioma_grading_clinical_and_mutation_features.data.features)\n",
    "y = pd.DataFrame(glioma_grading_clinical_and_mutation_features.data.targets)\n",
    "\n",
    "# metadata \n",
    "print(glioma_grading_clinical_and_mutation_features.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(glioma_grading_clinical_and_mutation_features.variables)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X['Race'] = X['Race'].map({'white': 0, 'black or african american': 1, 'asian': 2})\n",
    "\n",
    "# If there are NaN values in the 'Race' column, you can fill them with a default value, e.g., -1\n",
    "X['Race'] = X['Race'].fillna(-1).astype(int)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Select the top 10 features based on ANOVA F-statistic\n",
    "k_best = SelectKBest(score_func=f_classif, k=20)\n",
    "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = k_best.transform(X_test)  # Use the same k_best for transforming the test data\n",
    "\n",
    "\n",
    "print(y_test['Grade'].value_counts())\n",
    "# Assuming X_train has column names\n",
    "selected_feature_indices = k_best.get_support(indices=True)\n",
    "selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "#Getting only wanted feature columns\n",
    "X_train_selected = X_train[selected_feature_names]\n",
    "X_test_selected = X_test[selected_feature_names]\n",
    "\n",
    "print(\"Selected Feature Names:\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "print(\"Selected Feature Indices:\")\n",
    "print(selected_feature_indices)\n",
    "\n",
    "# Number of selected features\n",
    "num_selected_features = len(selected_feature_indices)\n",
    "\n",
    "# Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale feature\n",
    "X_train_selected_scaled = minmax_scale.fit_transform(X_train_selected) \n",
    "X_test_selected_scaled = minmax_scale.fit_transform(X_test_selected) \n",
    "\n",
    "# Build neural network using a sequential model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Add the input and first hidden layer\n",
    "    tf.keras.layers.Dense(30, input_shape=(num_selected_features,), activation=\"sigmoid\"),\n",
    "    # Add the second hidden layer\n",
    "    tf.keras.layers.Dense(15, activation=\"sigmoid\"),\n",
    "    # Add the output layer with the correct number of nodes\n",
    "    tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model with the correct output layer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "X_train_selected_scaled_df = pd.DataFrame(X_train_selected_scaled, columns=selected_feature_names)\n",
    "X_test_selected_scaled_df = pd.DataFrame(X_test_selected_scaled, columns=selected_feature_names)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "model.fit(X_train_selected, y_train, epochs=5000, validation_data=(X_test_selected, y_test), callbacks=[early_stopping])\n",
    "#model.fit(X_train_selected, y_train, epochs=5000) #5000\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using evaluate\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test_selected, y_test)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "#Saving the model\n",
    "import os\n",
    "path = os.path.dirname(os.path.realpath(__file__))\n",
    "print(\"current directory:\", path)\n",
    "import joblib \n",
    "joblib.dump(model, path+'\\\\tumors_model.pkl')\n",
    "print(\"Model dumped!\")\n",
    "# Save the k_best object\n",
    "\n",
    "joblib.dump(k_best, path+'\\\\''k_best.pkl')\n",
    "print(\"k best dumped dumped!\")\n",
    "\n",
    "model_columns = list(X_train_selected_scaled_df.columns)\n",
    "print(model_columns)\n",
    "joblib.dump(model_columns, path+'\\\\tumors_model_columns.pkl')\n",
    "print(\"Models columns dumped!\")\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(X_test_selected)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted Labels:\")\n",
    "print(predicted_labels)\n",
    "\n",
    "user_input = {\n",
    "    'Age_at_diagnosis': 53.65, \n",
    "     'Race': 0, \n",
    "     'IDH1': 0, \n",
    "     'TP53': 1, \n",
    "     'ATRX': 1, \n",
    "     'PTEN': 1, \n",
    "     'EGFR': 1, \n",
    "     'CIC': 1, \n",
    "     'MUC16': 1, \n",
    "     'PIK3CA': 0, \n",
    "     'NF1': 1, \n",
    "     'PIK3R1': 1, \n",
    "     'FUBP1': 0, \n",
    "     'RB1': 1, \n",
    "     'NOTCH1': 0, \n",
    "     'CSMD3': 1, \n",
    "     'SMARCA4': 0, \n",
    "     'GRIN2A': 1, \n",
    "     'IDH2': 0, \n",
    "     'PDGFRA': 1\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the user input\n",
    "user_input_df = pd.DataFrame([user_input])\n",
    "print(X_test_selected)\n",
    "\n",
    "# Select only the relevant features\n",
    "#user_input_selected = user_input_df[selected_feature_names]\n",
    "# Create a DataFrame from the user input with the correct column names\n",
    "user_input_df = pd.DataFrame([user_input], columns=selected_feature_names)\n",
    "\n",
    "# Scale the input features using the same scaler used during training\n",
    "user_input_scaled = minmax_scale.transform(user_input_df)\n",
    "\n",
    "# Scale the input features using the same scaler used during training\n",
    "# = minmax_scale.transform(user_input_selected)\n",
    "# Make predictions\n",
    "user_predictions = model.predict(user_input_scaled)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "user_predicted_label = np.argmax(user_predictions)\n",
    "\n",
    "\n",
    "\n",
    "print(\"User Predictions label:\", user_predicted_label)\n",
    "print(\"User Predictions:\", user_predictions)\n",
    "\n",
    "for data in X_test_selected.values:\n",
    "    print(data)\n",
    "    # Select only the relevant features\n",
    "    #user_input_selected = user_input_df[selected_feature_names]\n",
    "    # Create a DataFrame from the user input with the correct column names\n",
    "    user_input_df = pd.DataFrame([data], columns=selected_feature_names)\n",
    "    \n",
    "    # Scale the input features using the same scaler used during training\n",
    "    user_input_scaled = minmax_scale.transform(user_input_df)\n",
    "    \n",
    "    # Scale the input features using the same scaler used during training\n",
    "    # = minmax_scale.transform(user_input_selected)\n",
    "    # Make predictions\n",
    "    user_predictions = model.predict(user_input_scaled)\n",
    "    \n",
    "    # Convert the predictions to class labels\n",
    "    user_predicted_label = np.argmax(user_predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"User Predictions label:\", user_predicted_label)\n",
    "    print(\"User Predictions:\", user_predictions)\n",
    "    # Check if user_predicted_label is 1 and break the loop\n",
    "    if user_predicted_label == 1:\n",
    "       print(\"Breaking the loop because user_predicted_label is 1\")\n",
    "       break\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
