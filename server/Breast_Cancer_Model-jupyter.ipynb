{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "Y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "print(X.head(10))\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform the target variable to 0 and 1\n",
    "y=label_encoder.fit_transform(Y)\n",
    "# Retrieve the original class labels\n",
    "original_labels = label_encoder.classes_\n",
    "\n",
    "# Print the mapping\n",
    "print(f\"Label 0 corresponds to: {original_labels[0]}\")\n",
    "print(f\"Label 1 corresponds to: {original_labels[1]}\")\n",
    "\n",
    "\n",
    "\n",
    "print(y)\n",
    "\n",
    "# print(y)\n",
    "  \n",
    "# # metadata \n",
    "# print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# # variable information \n",
    "# print(breast_cancer_wisconsin_diagnostic.variables) \n",
    "\n",
    "# print('X')\n",
    "# print(X.columns)\n",
    "# print(X.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y_test)\n",
    "\n",
    "# Select the top 10 features based on ANOVA F-statistic\n",
    "k_best = SelectKBest(score_func=f_classif, k=10)\n",
    "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = k_best.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train_selected.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X_train has column names\n",
    "selected_feature_indices = k_best.get_support(indices=True)\n",
    "selected_feature_names = X_train.columns[selected_feature_indices]\n",
    "\n",
    "#Getting only wanted feature columns\n",
    "X_train_selected = X_train[selected_feature_names]\n",
    "X_test_selected = X_test[selected_feature_names]\n",
    "\n",
    "print(X_train_selected)\n",
    "\n",
    "# print(\"Selected Feature Names:\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "print(\"Selected Feature Indices:\")\n",
    "print(selected_feature_indices)\n",
    "\n",
    "print(\"X_train_selected:\")\n",
    "print(X_train_selected)\n",
    "\n",
    "\n",
    "# Number of selected features\n",
    "num_selected_features = len(selected_feature_indices)\n",
    "\n",
    "# Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "# Scale feature\n",
    "X_train_selected_scaled = minmax_scale.fit_transform(X_train_selected) \n",
    "X_test_selected_scaled = minmax_scale.fit_transform(X_test_selected) \n",
    "print(\"X_train_selected:\")\n",
    "print(X_train_selected)\n",
    "\n",
    "# # Create scaler\n",
    "# standard_scaler = StandardScaler()\n",
    "\n",
    "# # Scale features\n",
    "# X_train_scaled = standard_scaler.fit_transform(X_train)\n",
    "# X_test_scaled = standard_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Build neural network using a sequential model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Add the input and first hidden layer\n",
    "    tf.keras.layers.Dense(30, input_shape=(num_selected_features,), activation=\"sigmoid\"),\n",
    "    # Add the second hidden layer\n",
    "    tf.keras.layers.Dense(15, activation=\"sigmoid\"),\n",
    "    # Add the output layer\n",
    "    tf.keras.layers.Dense(2, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "print('X train selected')\n",
    "print(X_train_selected)\n",
    "\n",
    "X_train_selected_scaled_df = pd.DataFrame(X_train_selected_scaled, columns=selected_feature_names)\n",
    "X_test_selected_scaled_df = pd.DataFrame(X_test_selected_scaled, columns=selected_feature_names)\n",
    "\n",
    "print(X_train_selected_scaled_df)\n",
    "print(X_test_selected_scaled_df)\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "model.fit(X_train_selected_scaled_df, y_train, epochs=5000, validation_data=(X_test_selected_scaled_df, y_test), callbacks=[early_stopping])\n",
    "#model.fit(X_train_selected, y_train, epochs=5000) #5000\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test_selected_scaled_df, y_test)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "#Saving the model\n",
    "import os\n",
    "path = os.path.dirname(os.path.realpath(__file__))\n",
    "print(\"current directory:\", path)\n",
    "import joblib \n",
    "joblib.dump(model, path+'\\\\model_breast_cancer.pkl')\n",
    "print(\"Model dumped!\")\n",
    "# Save the k_best object\n",
    "\n",
    "joblib.dump(k_best, path+'\\\\''k_best.pkl')\n",
    "print(\"Models columns dumped!\")\n",
    "\n",
    "model_columns = list(X_train_selected_scaled_df.columns)\n",
    "print(model_columns)\n",
    "joblib.dump(model_columns, path+'\\\\model_breast_cancer_columns.pkl')\n",
    "print(\"Models columns dumped!\")\n",
    "\n",
    "\n",
    "user_input={\n",
    "  \"radius1\": 13.54,\n",
    "  \"perimeter1\": 14.36,\n",
    "  \"area1\": 87.46,\n",
    "  \"concavity1\": 0.09779,\n",
    "  \"concave_points1\": 0.08129,\n",
    "  \"radius3\": 15.76,\n",
    "  \"perimeter3\": 102.5,\n",
    "  \"area3\": 764.0,\n",
    "  \"concavity3\": 0.1234,\n",
    "  \"concave_points3\": 0.0678\n",
    "\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the user input\n",
    "user_input_df = pd.DataFrame([user_input])\n",
    "\n",
    "# Select only the relevant features\n",
    "user_input_selected = user_input_df[selected_feature_names]\n",
    "\n",
    "# Scale the input features using the same scaler used during training\n",
    "user_input_scaled = minmax_scale.transform(user_input_selected)\n",
    "\n",
    "# Make predictions\n",
    "user_predictions = model.predict(user_input_scaled)\n",
    "print(user_predictions)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "user_predicted_label = np.argmax(user_predictions)\n",
    "\n",
    "print(\"User Predicted Label:\", user_predicted_label)\n",
    "\n",
    "print('DF COLUMN NAMES')\n",
    "print(X_train_selected_scaled_df.columns)\n",
    "\n",
    "print(model_columns)\n",
    "\n",
    "\n",
    "for data in X_test_selected.values:\n",
    "    print(data)\n",
    "    # Select only the relevant features\n",
    "    #user_input_selected = user_input_df[selected_feature_names]\n",
    "    # Create a DataFrame from the user input with the correct column names\n",
    "    user_input_df = pd.DataFrame([data], columns=selected_feature_names)\n",
    "    \n",
    "    # Scale the input features using the same scaler used during training\n",
    "    user_input_scaled = minmax_scale.transform(user_input_df)\n",
    "    \n",
    "    # Scale the input features using the same scaler used during training\n",
    "    # = minmax_scale.transform(user_input_selected)\n",
    "    # Make predictions\n",
    "    user_predictions = model.predict(user_input_scaled)\n",
    "    \n",
    "    # Convert the predictions to class labels\n",
    "    user_predicted_label = np.argmax(user_predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"User Predictions label:\", user_predicted_label)\n",
    "    print(\"User Predictions:\", user_predictions)\n",
    "    # Check if user_predicted_label is 1 and break the loop\n",
    "    if user_predicted_label == 1:\n",
    "       print(\"Breaking the loop because user_predicted_label is 1\")\n",
    "       break\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
